ssh://bureaux@172.30.2.148:22/home/bureaux/miniconda3/envs/Keras-base/bin/python -u /home/bureaux/.pycharm_helpers/pydev/pydevconsole.py --mode=server
import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/bureaux/Projects/keras4bert', '/home/bureaux/Projects/keras4bert'])
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59)
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
runfile('/home/bureaux/Projects/keras4bert/Classification/train.py', wdir='/home/bureaux/Projects/keras4bert/Classification')
PyDev console: using IPython 7.16.1
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59)
[GCC 7.5.0] on linux
Using TensorFlow backend.
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, None)         0
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, None)         0
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 256)    5408768     Input-Token[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 256)    512         Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 256)    0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 256)    131072      Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 256)    512         Embedding-Position[0][0]
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 256)    0           Embedding-Norm[0][0]
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 256)    263168      Embedding-Dropout[0][0]
                                                                 Embedding-Dropout[0][0]
                                                                 Embedding-Dropout[0][0]
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 256)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 256)    0           Embedding-Dropout[0][0]
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 256)    512         Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 256)    525568      Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 256)    0           Transformer-0-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 256)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 256)    512         Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 256)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 256)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 256)    512         Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 256)    525568      Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 256)    0           Transformer-1-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 256)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 256)    512         Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 256)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 256)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 256)    512         Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 256)    525568      Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 256)    0           Transformer-2-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 256)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 256)    512         Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 256)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 256)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 256)    512         Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 256)    525568      Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 256)    0           Transformer-3-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 256)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 256)    512         Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 256)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 256)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 256)    512         Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 256)    525568      Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 256)    0           Transformer-4-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 256)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 256)    512         Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 256)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 256)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 256)    512         Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 256)    525568      Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 256)    0           Transformer-5-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 256)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 256)    512         Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 256)    0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 256)    0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 256)    512         Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 256)    525568      Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 256)    0           Transformer-6-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 256)    0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 256)    512         Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 256)    0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 256)    0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 256)    512         Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 256)    525568      Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 256)    0           Transformer-7-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 256)    0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 256)    512         Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 256)    0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 256)    0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 256)    512         Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 256)    525568      Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 256)    0           Transformer-8-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 256)    0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 256)    512         Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 256)    0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 256)    0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 256)    512         Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 256)    525568      Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 256)    0           Transformer-9-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 256)    0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 256)    512         Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 256)    0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 256)    0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 256)    512         Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 256)    525568      Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 256)    0           Transformer-10-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 256)    0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 256)    512         Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 256)    0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 256)    0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 256)    512         Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 256)    525568      Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 256)    0           Transformer-11-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 256)    0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 256)    512         Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-11-FeedForward-Norm[0
                                                                 Transformer-11-FeedForward-Norm[0
                                                                 Transformer-11-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 256)    0           Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 256)    0           Transformer-11-FeedForward-Norm[0
                                                                 Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 256)    512         Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-FeedForward (Fee (None, None, 256)    525568      Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-FeedForward-Drop (None, None, 256)    0           Transformer-12-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-12-FeedForward-Add  (None, None, 256)    0           Transformer-12-MultiHeadSelfAtten
                                                                 Transformer-12-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-12-FeedForward-Norm (None, None, 256)    512         Transformer-12-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-12-FeedForward-Norm[0
                                                                 Transformer-12-FeedForward-Norm[0
                                                                 Transformer-12-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 256)    0           Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 256)    0           Transformer-12-FeedForward-Norm[0
                                                                 Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 256)    512         Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-FeedForward (Fee (None, None, 256)    525568      Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-FeedForward-Drop (None, None, 256)    0           Transformer-13-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-13-FeedForward-Add  (None, None, 256)    0           Transformer-13-MultiHeadSelfAtten
                                                                 Transformer-13-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-13-FeedForward-Norm (None, None, 256)    512         Transformer-13-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-13-FeedForward-Norm[0
                                                                 Transformer-13-FeedForward-Norm[0
                                                                 Transformer-13-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 256)    0           Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 256)    0           Transformer-13-FeedForward-Norm[0
                                                                 Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 256)    512         Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-FeedForward (Fee (None, None, 256)    525568      Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-FeedForward-Drop (None, None, 256)    0           Transformer-14-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-14-FeedForward-Add  (None, None, 256)    0           Transformer-14-MultiHeadSelfAtten
                                                                 Transformer-14-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-14-FeedForward-Norm (None, None, 256)    512         Transformer-14-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-14-FeedForward-Norm[0
                                                                 Transformer-14-FeedForward-Norm[0
                                                                 Transformer-14-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 256)    0           Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 256)    0           Transformer-14-FeedForward-Norm[0
                                                                 Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 256)    512         Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-FeedForward (Fee (None, None, 256)    525568      Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-FeedForward-Drop (None, None, 256)    0           Transformer-15-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-15-FeedForward-Add  (None, None, 256)    0           Transformer-15-MultiHeadSelfAtten
                                                                 Transformer-15-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-15-FeedForward-Norm (None, None, 256)    512         Transformer-15-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-15-FeedForward-Norm[0
                                                                 Transformer-15-FeedForward-Norm[0
                                                                 Transformer-15-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 256)    0           Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 256)    0           Transformer-15-FeedForward-Norm[0
                                                                 Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 256)    512         Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-FeedForward (Fee (None, None, 256)    525568      Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-FeedForward-Drop (None, None, 256)    0           Transformer-16-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-16-FeedForward-Add  (None, None, 256)    0           Transformer-16-MultiHeadSelfAtten
                                                                 Transformer-16-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-16-FeedForward-Norm (None, None, 256)    512         Transformer-16-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-16-FeedForward-Norm[0
                                                                 Transformer-16-FeedForward-Norm[0
                                                                 Transformer-16-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 256)    0           Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 256)    0           Transformer-16-FeedForward-Norm[0
                                                                 Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 256)    512         Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-FeedForward (Fee (None, None, 256)    525568      Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-FeedForward-Drop (None, None, 256)    0           Transformer-17-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-17-FeedForward-Add  (None, None, 256)    0           Transformer-17-MultiHeadSelfAtten
                                                                 Transformer-17-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-17-FeedForward-Norm (None, None, 256)    512         Transformer-17-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-17-FeedForward-Norm[0
                                                                 Transformer-17-FeedForward-Norm[0
                                                                 Transformer-17-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 256)    0           Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 256)    0           Transformer-17-FeedForward-Norm[0
                                                                 Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 256)    512         Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-FeedForward (Fee (None, None, 256)    525568      Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-FeedForward-Drop (None, None, 256)    0           Transformer-18-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-18-FeedForward-Add  (None, None, 256)    0           Transformer-18-MultiHeadSelfAtten
                                                                 Transformer-18-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-18-FeedForward-Norm (None, None, 256)    512         Transformer-18-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-18-FeedForward-Norm[0
                                                                 Transformer-18-FeedForward-Norm[0
                                                                 Transformer-18-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 256)    0           Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 256)    0           Transformer-18-FeedForward-Norm[0
                                                                 Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 256)    512         Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-FeedForward (Fee (None, None, 256)    525568      Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-FeedForward-Drop (None, None, 256)    0           Transformer-19-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-19-FeedForward-Add  (None, None, 256)    0           Transformer-19-MultiHeadSelfAtten
                                                                 Transformer-19-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-19-FeedForward-Norm (None, None, 256)    512         Transformer-19-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-19-FeedForward-Norm[0
                                                                 Transformer-19-FeedForward-Norm[0
                                                                 Transformer-19-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 256)    0           Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 256)    0           Transformer-19-FeedForward-Norm[0
                                                                 Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 256)    512         Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-FeedForward (Fee (None, None, 256)    525568      Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-FeedForward-Drop (None, None, 256)    0           Transformer-20-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-20-FeedForward-Add  (None, None, 256)    0           Transformer-20-MultiHeadSelfAtten
                                                                 Transformer-20-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-20-FeedForward-Norm (None, None, 256)    512         Transformer-20-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-20-FeedForward-Norm[0
                                                                 Transformer-20-FeedForward-Norm[0
                                                                 Transformer-20-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 256)    0           Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 256)    0           Transformer-20-FeedForward-Norm[0
                                                                 Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 256)    512         Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-FeedForward (Fee (None, None, 256)    525568      Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-FeedForward-Drop (None, None, 256)    0           Transformer-21-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-21-FeedForward-Add  (None, None, 256)    0           Transformer-21-MultiHeadSelfAtten
                                                                 Transformer-21-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-21-FeedForward-Norm (None, None, 256)    512         Transformer-21-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-21-FeedForward-Norm[0
                                                                 Transformer-21-FeedForward-Norm[0
                                                                 Transformer-21-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 256)    0           Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 256)    0           Transformer-21-FeedForward-Norm[0
                                                                 Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 256)    512         Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-FeedForward (Fee (None, None, 256)    525568      Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-FeedForward-Drop (None, None, 256)    0           Transformer-22-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-22-FeedForward-Add  (None, None, 256)    0           Transformer-22-MultiHeadSelfAtten
                                                                 Transformer-22-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-22-FeedForward-Norm (None, None, 256)    512         Transformer-22-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 256)    263168      Transformer-22-FeedForward-Norm[0
                                                                 Transformer-22-FeedForward-Norm[0
                                                                 Transformer-22-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 256)    0           Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 256)    0           Transformer-22-FeedForward-Norm[0
                                                                 Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 256)    512         Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-FeedForward (Fee (None, None, 256)    525568      Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-FeedForward-Drop (None, None, 256)    0           Transformer-23-FeedForward[0][0]
__________________________________________________________________________________________________
Transformer-23-FeedForward-Add  (None, None, 256)    0           Transformer-23-MultiHeadSelfAtten
                                                                 Transformer-23-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-23-FeedForward-Norm (None, None, 256)    512         Transformer-23-FeedForward-Add[0]
__________________________________________________________________________________________________
CLS-token (Lambda)              (None, 256)          0           Transformer-23-FeedForward-Norm[0
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 3)            771         CLS-token[0][0]
==================================================================================================
Total params: 24,495,875
Trainable params: 24,495,875
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Epoch 1/200
134/134 [==============================] - 112s 836ms/step - loss: 1.0067 - acc: 0.5221 - val_loss: 0.6746 - val_acc: 0.7660
val_acc: 0.76605, best_val_acc: 0.76605, test_acc: 0.72931
Epoch 2/200
134/134 [==============================] - 75s 559ms/step - loss: 0.6296 - acc: 0.7556 - val_loss: 0.4127 - val_acc: 0.8624
val_acc: 0.86244, best_val_acc: 0.86244, test_acc: 0.85692
Epoch 3/200
134/134 [==============================] - 87s 647ms/step - loss: 0.4027 - acc: 0.8689 - val_loss: 0.3024 - val_acc: 0.8995
val_acc: 0.89949, best_val_acc: 0.89949, test_acc: 0.89113
Epoch 4/200
134/134 [==============================] - 88s 657ms/step - loss: 0.3357 - acc: 0.8829 - val_loss: 0.2448 - val_acc: 0.9092
val_acc: 0.90918, best_val_acc: 0.90918, test_acc: 0.90204
Epoch 5/200
134/134 [==============================] - 89s 666ms/step - loss: 0.2896 - acc: 0.8900 - val_loss: 0.1762 - val_acc: 0.9283
val_acc: 0.92831, best_val_acc: 0.92831, test_acc: 0.91448
Epoch 6/200
134/134 [==============================] - 89s 664ms/step - loss: 0.2434 - acc: 0.9021 - val_loss: 0.1325 - val_acc: 0.9361
val_acc: 0.93606, best_val_acc: 0.93606, test_acc: 0.92113
Epoch 7/200
134/134 [==============================] - 90s 675ms/step - loss: 0.2169 - acc: 0.9093 - val_loss: 0.1249 - val_acc: 0.9487
val_acc: 0.94866, best_val_acc: 0.94866, test_acc: 0.92604
Epoch 8/200
134/134 [==============================] - 89s 663ms/step - loss: 0.2237 - acc: 0.9041 - val_loss: 0.1283 - val_acc: 0.9402
val_acc: 0.94018, best_val_acc: 0.94866, test_acc: 0.92131
Epoch 9/200
134/134 [==============================] - 88s 660ms/step - loss: 0.2155 - acc: 0.9077 - val_loss: 0.0755 - val_acc: 0.9525
val_acc: 0.95253, best_val_acc: 0.95253, test_acc: 0.93649
Epoch 10/200
134/134 [==============================] - 88s 660ms/step - loss: 0.1549 - acc: 0.9259 - val_loss: 0.0529 - val_acc: 0.9707
val_acc: 0.97070, best_val_acc: 0.97070, test_acc: 0.93549
Epoch 11/200
134/134 [==============================] - 88s 658ms/step - loss: 0.1351 - acc: 0.9321 - val_loss: 0.0541 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94040
Epoch 12/200
134/134 [==============================] - 83s 621ms/step - loss: 0.1214 - acc: 0.9328 - val_loss: 0.0572 - val_acc: 0.9542
val_acc: 0.95423, best_val_acc: 0.97070, test_acc: 0.94081
Epoch 13/200
134/134 [==============================] - 90s 672ms/step - loss: 0.1095 - acc: 0.9359 - val_loss: 0.0423 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94267
Epoch 14/200
134/134 [==============================] - 90s 674ms/step - loss: 0.1047 - acc: 0.9400 - val_loss: 0.0444 - val_acc: 0.9566
val_acc: 0.95665, best_val_acc: 0.97070, test_acc: 0.94285
Epoch 15/200
134/134 [==============================] - 91s 680ms/step - loss: 0.1008 - acc: 0.9407 - val_loss: 0.0409 - val_acc: 0.9591
val_acc: 0.95907, best_val_acc: 0.97070, test_acc: 0.94273
Epoch 16/200
134/134 [==============================] - 89s 663ms/step - loss: 0.0985 - acc: 0.9412 - val_loss: 0.0417 - val_acc: 0.9566
val_acc: 0.95665, best_val_acc: 0.97070, test_acc: 0.94308
Epoch 17/200
134/134 [==============================] - 89s 663ms/step - loss: 0.0992 - acc: 0.9400 - val_loss: 0.0420 - val_acc: 0.9552
val_acc: 0.95519, best_val_acc: 0.97070, test_acc: 0.94332
Epoch 18/200
134/134 [==============================] - 90s 670ms/step - loss: 0.0977 - acc: 0.9412 - val_loss: 0.0404 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94326
Epoch 19/200
134/134 [==============================] - 89s 662ms/step - loss: 0.0964 - acc: 0.9399 - val_loss: 0.0405 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94320
Epoch 20/200
134/134 [==============================] - 89s 663ms/step - loss: 0.0966 - acc: 0.9413 - val_loss: 0.0389 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94337
Epoch 21/200
134/134 [==============================] - 89s 668ms/step - loss: 0.0956 - acc: 0.9413 - val_loss: 0.0395 - val_acc: 0.9557
val_acc: 0.95568, best_val_acc: 0.97070, test_acc: 0.94337
Epoch 22/200
134/134 [==============================] - 89s 666ms/step - loss: 0.0955 - acc: 0.9398 - val_loss: 0.0390 - val_acc: 0.9562
val_acc: 0.95616, best_val_acc: 0.97070, test_acc: 0.94343
Epoch 23/200
134/134 [==============================] - 89s 666ms/step - loss: 0.0953 - acc: 0.9404 - val_loss: 0.0389 - val_acc: 0.9564
val_acc: 0.95641, best_val_acc: 0.97070, test_acc: 0.94343
Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
Epoch 24/200
134/134 [==============================] - 88s 660ms/step - loss: 0.0937 - acc: 0.9418 - val_loss: 0.0373 - val_acc: 0.9569
val_acc: 0.95689, best_val_acc: 0.97070, test_acc: 0.94343
Epoch 25/200
134/134 [==============================] - 91s 681ms/step - loss: 0.0936 - acc: 0.9427 - val_loss: 0.0407 - val_acc: 0.9557
val_acc: 0.95568, best_val_acc: 0.97070, test_acc: 0.94343
Epoch 26/200
134/134 [==============================] - 90s 668ms/step - loss: 0.0932 - acc: 0.9422 - val_loss: 0.0388 - val_acc: 0.9562
val_acc: 0.95616, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 27/200
134/134 [==============================] - 90s 668ms/step - loss: 0.0936 - acc: 0.9410 - val_loss: 0.0390 - val_acc: 0.9559
val_acc: 0.95592, best_val_acc: 0.97070, test_acc: 0.94343
Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
Epoch 28/200
134/134 [==============================] - 89s 663ms/step - loss: 0.0925 - acc: 0.9427 - val_loss: 0.0382 - val_acc: 0.9571
val_acc: 0.95713, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 29/200
134/134 [==============================] - 89s 664ms/step - loss: 0.0918 - acc: 0.9439 - val_loss: 0.0386 - val_acc: 0.9559
val_acc: 0.95592, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 30/200
134/134 [==============================] - 88s 658ms/step - loss: 0.0935 - acc: 0.9423 - val_loss: 0.0393 - val_acc: 0.9564
val_acc: 0.95641, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.
Epoch 31/200
134/134 [==============================] - 90s 673ms/step - loss: 0.0926 - acc: 0.9424 - val_loss: 0.0394 - val_acc: 0.9564
val_acc: 0.95641, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 32/200
134/134 [==============================] - 90s 669ms/step - loss: 0.0922 - acc: 0.9432 - val_loss: 0.0390 - val_acc: 0.9562
val_acc: 0.95616, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 33/200
134/134 [==============================] - 88s 659ms/step - loss: 0.0921 - acc: 0.9434 - val_loss: 0.0391 - val_acc: 0.9562
val_acc: 0.95616, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.
Epoch 34/200
134/134 [==============================] - 88s 660ms/step - loss: 0.0923 - acc: 0.9424 - val_loss: 0.0388 - val_acc: 0.9562
val_acc: 0.95616, best_val_acc: 0.97070, test_acc: 0.94349
Epoch 00034: early stopping
final test acc: 0.943433
