ssh://bureaux@172.30.2.148:22/home/bureaux/miniconda3/envs/Keras-base/bin/python -u /home/bureaux/Projects/keras4bert/NER/tiny_train.py
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, None)         0
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, None)         0
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 312)    6591936     Input-Token[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 312)    624         Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 312)    0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 312)    159744      Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 312)    624         Embedding-Position[0][0]
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    390624      Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    0           Embedding-Norm[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    624         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 312)    780312      Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 312)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 312)    624         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, None, 64)     88320       Transformer-FeedForward-Norm[3][0
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 13)     845         bidirectional_1[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 13)     0           time_distributed_1[0][0]
__________________________________________________________________________________________________
conditional_random_field_1 (Con (None, None, 13)     169         dropout_1[0][0]
==================================================================================================
Total params: 8,014,446
Trainable params: 8,014,446
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.


		Train start!

Epoch 1/100
20/20 [==============================] - 72s 4s/step - loss: 183.0799 - sparse_accuracy: 0.0211 - val_loss: 135.1221 - val_sparse_accuracy: 0.6212
Epoch 2/100
20/20 [==============================] - 60s 3s/step - loss: 99.3482 - sparse_accuracy: 0.6344 - val_loss: 43.6756 - val_sparse_accuracy: 0.8070
Epoch 3/100
20/20 [==============================] - 59s 3s/step - loss: 39.6377 - sparse_accuracy: 0.7252 - val_loss: 26.7920 - val_sparse_accuracy: 0.8067
Epoch 4/100
20/20 [==============================] - 58s 3s/step - loss: 27.5383 - sparse_accuracy: 0.7280 - val_loss: 21.7087 - val_sparse_accuracy: 0.8066
Epoch 5/100
20/20 [==============================] - 58s 3s/step - loss: 24.2654 - sparse_accuracy: 0.7273 - val_loss: 19.2104 - val_sparse_accuracy: 0.8069
Epoch 6/100
20/20 [==============================] - 58s 3s/step - loss: 20.0311 - sparse_accuracy: 0.7343 - val_loss: 15.6232 - val_sparse_accuracy: 0.8234
Epoch 7/100
20/20 [==============================] - 57s 3s/step - loss: 16.2725 - sparse_accuracy: 0.7472 - val_loss: 12.3238 - val_sparse_accuracy: 0.8432
Epoch 8/100
20/20 [==============================] - 60s 3s/step - loss: 13.0132 - sparse_accuracy: 0.7634 - val_loss: 9.8020 - val_sparse_accuracy: 0.8571
Epoch 9/100
20/20 [==============================] - 59s 3s/step - loss: 10.2843 - sparse_accuracy: 0.7802 - val_loss: 7.9115 - val_sparse_accuracy: 0.8612
Epoch 10/100
20/20 [==============================] - 59s 3s/step - loss: 8.6531 - sparse_accuracy: 0.7929 - val_loss: 6.6703 - val_sparse_accuracy: 0.8789
Epoch 11/100
20/20 [==============================] - 54s 3s/step - loss: 7.4209 - sparse_accuracy: 0.8007 - val_loss: 6.0231 - val_sparse_accuracy: 0.8918
Epoch 12/100
20/20 [==============================] - 57s 3s/step - loss: 6.5797 - sparse_accuracy: 0.8134 - val_loss: 5.2788 - val_sparse_accuracy: 0.8908
Epoch 13/100
20/20 [==============================] - 57s 3s/step - loss: 5.5827 - sparse_accuracy: 0.8184 - val_loss: 4.8892 - val_sparse_accuracy: 0.8844
Epoch 14/100
20/20 [==============================] - 57s 3s/step - loss: 5.0605 - sparse_accuracy: 0.8316 - val_loss: 4.4626 - val_sparse_accuracy: 0.9000
Epoch 15/100
20/20 [==============================] - 55s 3s/step - loss: 4.7424 - sparse_accuracy: 0.8364 - val_loss: 4.4662 - val_sparse_accuracy: 0.8922
Epoch 16/100
20/20 [==============================] - 57s 3s/step - loss: 4.2567 - sparse_accuracy: 0.8470 - val_loss: 4.1071 - val_sparse_accuracy: 0.9019
Epoch 17/100
20/20 [==============================] - 59s 3s/step - loss: 3.9261 - sparse_accuracy: 0.8518 - val_loss: 4.0560 - val_sparse_accuracy: 0.8962
Epoch 18/100
20/20 [==============================] - 60s 3s/step - loss: 3.5092 - sparse_accuracy: 0.8674 - val_loss: 4.0410 - val_sparse_accuracy: 0.8962
Epoch 19/100
20/20 [==============================] - 56s 3s/step - loss: 3.2586 - sparse_accuracy: 0.8745 - val_loss: 3.9780 - val_sparse_accuracy: 0.9050
Epoch 20/100
20/20 [==============================] - 56s 3s/step - loss: 3.1808 - sparse_accuracy: 0.8750 - val_loss: 3.8816 - val_sparse_accuracy: 0.8987
Epoch 21/100
20/20 [==============================] - 54s 3s/step - loss: 2.8538 - sparse_accuracy: 0.8868 - val_loss: 3.7400 - val_sparse_accuracy: 0.9059
Epoch 22/100
20/20 [==============================] - 56s 3s/step - loss: 2.6008 - sparse_accuracy: 0.8963 - val_loss: 3.7450 - val_sparse_accuracy: 0.9056
Epoch 23/100
20/20 [==============================] - 60s 3s/step - loss: 2.4547 - sparse_accuracy: 0.9018 - val_loss: 3.7168 - val_sparse_accuracy: 0.9066
Epoch 24/100
20/20 [==============================] - 60s 3s/step - loss: 2.2967 - sparse_accuracy: 0.9002 - val_loss: 3.8106 - val_sparse_accuracy: 0.9145
Epoch 25/100
20/20 [==============================] - 58s 3s/step - loss: 2.0991 - sparse_accuracy: 0.9116 - val_loss: 3.7775 - val_sparse_accuracy: 0.9126
Epoch 26/100
20/20 [==============================] - 60s 3s/step - loss: 1.8889 - sparse_accuracy: 0.9149 - val_loss: 4.0070 - val_sparse_accuracy: 0.9187
Epoch 27/100
20/20 [==============================] - 60s 3s/step - loss: 1.8402 - sparse_accuracy: 0.9192 - val_loss: 3.9835 - val_sparse_accuracy: 0.9125
Epoch 28/100
20/20 [==============================] - 60s 3s/step - loss: 1.6821 - sparse_accuracy: 0.9235 - val_loss: 3.9332 - val_sparse_accuracy: 0.9199
Epoch 29/100
20/20 [==============================] - 59s 3s/step - loss: 1.5682 - sparse_accuracy: 0.9295 - val_loss: 4.2206 - val_sparse_accuracy: 0.9221
Epoch 30/100
20/20 [==============================] - 58s 3s/step - loss: 1.4437 - sparse_accuracy: 0.9326 - val_loss: 4.1509 - val_sparse_accuracy: 0.9193
Epoch 31/100
20/20 [==============================] - 58s 3s/step - loss: 1.4078 - sparse_accuracy: 0.9359 - val_loss: 4.3876 - val_sparse_accuracy: 0.9207
Epoch 32/100
20/20 [==============================] - 54s 3s/step - loss: 1.3057 - sparse_accuracy: 0.9398 - val_loss: 4.3997 - val_sparse_accuracy: 0.9301
Epoch 33/100
20/20 [==============================] - 55s 3s/step - loss: 1.2137 - sparse_accuracy: 0.9414 - val_loss: 4.3816 - val_sparse_accuracy: 0.9229
Epoch 00033: early stopping

		Train end!


进程已结束,退出代码0
