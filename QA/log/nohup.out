ssh://bureaux@180.169.131.147:22/home/bureaux/miniconda3/envs/Keras-base/bin/python -u /home/bureaux/Projects/keras4bert/QA/train.py
Using TensorFlow backend.
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2022-02-21 13:29:58.440795: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-02-21 13:29:58.449706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2022-02-21 13:29:58.957188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556c295d2d00 executing computations on platform CUDA. Devices:
2022-02-21 13:29:58.957248: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Graphics Device, Compute Capability 7.0
2022-02-21 13:29:58.960509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-02-21 13:29:58.963068: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556c2c46fd30 executing computations on platform Host. Devices:
2022-02-21 13:29:58.963103: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2022-02-21 13:29:58.964489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:
name: Graphics Device major: 7 minor: 0 memoryClockRate(GHz): 1.597
pciBusID: 0000:3b:00.0
2022-02-21 13:29:58.964873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2022-02-21 13:29:58.966638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2022-02-21 13:29:58.968291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2022-02-21 13:29:58.968667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2022-02-21 13:29:58.970936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2022-02-21 13:29:58.972671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2022-02-21 13:29:58.977701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2022-02-21 13:29:58.980094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2022-02-21 13:29:58.980146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2022-02-21 13:29:58.982000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-02-21 13:29:58.982028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0
2022-02-21 13:29:58.982046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N
2022-02-21 13:29:58.984748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30458 MB memory) -> physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:3b:00.0, compute capability: 7.0)
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, None)         0
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, None)         0
__________________________________________________________________________________________________
Embedding-Token (Embedding)     multiple             4238208     Input-Token[0][0]
                                                                 MLM-Norm[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 312)    624         Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 312)    0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 312)    159744      Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 312)    624         Embedding-Position[0][0]
__________________________________________________________________________________________________
Attention-UniLM-Mask (Lambda)   (None, 1, None, None 0           Input-Segment[0][0]
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    390624      Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Attention-UniLM-Mask[0][0]
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Attention-UniLM-Mask[0][0]
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Attention-UniLM-Mask[0][0]
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Attention-UniLM-Mask[0][0]
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    0           Embedding-Norm[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    624         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 312)    780312      Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 312)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 312)    624         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
__________________________________________________________________________________________________
MLM-Dense (Dense)               (None, None, 312)    97656       Transformer-FeedForward-Norm[3][0
__________________________________________________________________________________________________
MLM-Norm (LayerNormalization)   (None, None, 312)    624         MLM-Dense[0][0]
__________________________________________________________________________________________________
MLM-Bias (BiasAdd)              (None, None, 13584)  13584       Embedding-Token[1][0]
__________________________________________________________________________________________________
MLM-Activation (Activation)     (None, None, 13584)  0           MLM-Bias[0][0]
__________________________________________________________________________________________________
cross_entropy_1 (CrossEntropy)  (None, None, 13584)  0           Input-Token[0][0]
                                                                 Input-Segment[0][0]
                                                                 MLM-Activation[0][0]
==================================================================================================
Total params: 5,683,248
Trainable params: 5,683,248
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Epoch 1/100
2022-02-21 13:30:07.971050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
1000/1000 [==============================] - 750s 750ms/step - loss: 4.1325
Epoch 2/100
1000/1000 [==============================] - 815s 815ms/step - loss: 3.5779
Epoch 3/100
1000/1000 [==============================] - 816s 816ms/step - loss: 3.4407
Epoch 4/100
1000/1000 [==============================] - 816s 816ms/step - loss: 1.7107
Epoch 5/100
1000/1000 [==============================] - 818s 818ms/step - loss: 1.6160
Epoch 6/100
1000/1000 [==============================] - 820s 820ms/step - loss: 1.5483
Epoch 7/100
1000/1000 [==============================] - 816s 816ms/step - loss: 1.4946
Epoch 8/100
1000/1000 [==============================] - 813s 813ms/step - loss: 1.4483
Epoch 9/100
1000/1000 [==============================] - 818s 818ms/step - loss: 1.4079
Epoch 10/100
1000/1000 [==============================] - 820s 820ms/step - loss: 1.3391
Epoch 11/100
1000/1000 [==============================] - 819s 819ms/step - loss: 1.2942
Epoch 12/100
1000/1000 [==============================] - 827s 827ms/step - loss: 1.2606
Epoch 13/100
1000/1000 [==============================] - 817s 817ms/step - loss: 1.2299
Epoch 14/100
1000/1000 [==============================] - 817s 817ms/step - loss: 1.1978
Epoch 15/100
1000/1000 [==============================] - 817s 817ms/step - loss: 1.1605
Epoch 16/100
1000/1000 [==============================] - 819s 819ms/step - loss: 1.1354
Epoch 17/100
1000/1000 [==============================] - 817s 817ms/step - loss: 1.1121
Epoch 18/100
1000/1000 [==============================] - 813s 813ms/step - loss: 1.0902
Epoch 19/100
1000/1000 [==============================] - 811s 811ms/step - loss: 1.0591
Epoch 20/100
1000/1000 [==============================] - 805s 805ms/step - loss: 1.0346
Epoch 21/100
1000/1000 [==============================] - 804s 804ms/step - loss: 1.0147
Epoch 22/100
1000/1000 [==============================] - 797s 797ms/step - loss: 0.9974
Epoch 23/100
1000/1000 [==============================] - 805s 805ms/step - loss: 0.9768
Epoch 24/100
1000/1000 [==============================] - 797s 797ms/step - loss: 0.9507
Epoch 25/100
1000/1000 [==============================] - 793s 793ms/step - loss: 0.9349
Epoch 26/100
1000/1000 [==============================] - 795s 795ms/step - loss: 0.9200
Epoch 27/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.9057
Epoch 28/100
1000/1000 [==============================] - 794s 794ms/step - loss: 0.8858
Epoch 29/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.8658
Epoch 30/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.8538
Epoch 31/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.8410
Epoch 32/100
1000/1000 [==============================] - 792s 792ms/step - loss: 0.8296
Epoch 33/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.8072
Epoch 34/100
1000/1000 [==============================] - 789s 789ms/step - loss: 0.7966
Epoch 35/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.7860
Epoch 36/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.7765
Epoch 37/100
1000/1000 [==============================] - 794s 794ms/step - loss: 0.7600
Epoch 38/100
1000/1000 [==============================] - 789s 789ms/step - loss: 0.7461
Epoch 39/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.7386
Epoch 40/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.7272
Epoch 41/100
1000/1000 [==============================] - 795s 795ms/step - loss: 0.7212
Epoch 42/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.7009
Epoch 43/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.6938
Epoch 44/100
1000/1000 [==============================] - 788s 788ms/step - loss: 0.6856
Epoch 45/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.6812
Epoch 46/100
1000/1000 [==============================] - 790s 790ms/step - loss: 0.6673
Epoch 47/100
1000/1000 [==============================] - 786s 786ms/step - loss: 0.6546
Epoch 48/100
1000/1000 [==============================] - 783s 783ms/step - loss: 0.6503
Epoch 49/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.6416
Epoch 50/100
1000/1000 [==============================] - 783s 783ms/step - loss: 0.6378
Epoch 51/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.6201
Epoch 52/100
1000/1000 [==============================] - 783s 783ms/step - loss: 0.6139
Epoch 53/100
1000/1000 [==============================] - 782s 782ms/step - loss: 0.6102
Epoch 54/100
1000/1000 [==============================] - 775s 775ms/step - loss: 0.6038
Epoch 55/100
1000/1000 [==============================] - 786s 786ms/step - loss: 0.5969
Epoch 56/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.5840
Epoch 57/100
1000/1000 [==============================] - 777s 777ms/step - loss: 0.5778
Epoch 58/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5752
Epoch 59/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.5732
Epoch 60/100
1000/1000 [==============================] - 782s 782ms/step - loss: 0.5570
Epoch 61/100
1000/1000 [==============================] - 777s 777ms/step - loss: 0.5526
Epoch 62/100
1000/1000 [==============================] - 782s 782ms/step - loss: 0.5467
Epoch 63/100
1000/1000 [==============================] - 779s 779ms/step - loss: 0.5444
Epoch 64/100
1000/1000 [==============================] - 783s 783ms/step - loss: 0.5391
Epoch 65/100
1000/1000 [==============================] - 776s 776ms/step - loss: 0.5270
Epoch 66/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5217
Epoch 67/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5215
Epoch 68/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5194
Epoch 69/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5055
Epoch 70/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.5009
Epoch 71/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.4991
Epoch 72/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.4960
Epoch 73/100
1000/1000 [==============================] - 778s 778ms/step - loss: 0.4921
Epoch 74/100
1000/1000 [==============================] - 778s 778ms/step - loss: 0.4794
Epoch 75/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.4774
Epoch 76/100
1000/1000 [==============================] - 776s 776ms/step - loss: 0.4748
Epoch 77/100
1000/1000 [==============================] - 777s 777ms/step - loss: 0.4750
Early stop count 1/5
Epoch 78/100
1000/1000 [==============================] - 782s 782ms/step - loss: 0.4654
Epoch 79/100
1000/1000 [==============================] - 780s 780ms/step - loss: 0.4576
Epoch 80/100
1000/1000 [==============================] - 781s 781ms/step - loss: 0.4582
Early stop count 1/5
Epoch 81/100
1000/1000 [==============================] - 784s 784ms/step - loss: 0.4546
Epoch 82/100
1000/1000 [==============================] - 788s 788ms/step - loss: 0.4541
Epoch 83/100
1000/1000 [==============================] - 789s 789ms/step - loss: 0.4422
Epoch 84/100
1000/1000 [==============================] - 793s 793ms/step - loss: 0.4400
Epoch 85/100
1000/1000 [==============================] - 792s 792ms/step - loss: 0.4369
Epoch 86/100
1000/1000 [==============================] - 789s 789ms/step - loss: 0.4389
Early stop count 1/5
Epoch 87/100
1000/1000 [==============================] - 798s 798ms/step - loss: 0.4306
Epoch 88/100
1000/1000 [==============================] - 800s 800ms/step - loss: 0.4230
Epoch 89/100
1000/1000 [==============================] - 801s 801ms/step - loss: 0.4226
Epoch 90/100
1000/1000 [==============================] - 803s 803ms/step - loss: 0.4210
Epoch 91/100
1000/1000 [==============================] - 806s 806ms/step - loss: 0.4214
Early stop count 1/5
Epoch 92/100
1000/1000 [==============================] - 804s 804ms/step - loss: 0.4094
Epoch 93/100
1000/1000 [==============================] - 807s 807ms/step - loss: 0.4069
Epoch 94/100
1000/1000 [==============================] - 805s 805ms/step - loss: 0.4070
Early stop count 1/5
Epoch 95/100
1000/1000 [==============================] - 807s 807ms/step - loss: 0.4072
Early stop count 2/5
Epoch 96/100
1000/1000 [==============================] - 813s 813ms/step - loss: 0.4009
Epoch 97/100
1000/1000 [==============================] - 813s 813ms/step - loss: 0.3940
Epoch 98/100
1000/1000 [==============================] - 812s 812ms/step - loss: 0.3941
Early stop count 1/5
Epoch 99/100
1000/1000 [==============================] - 814s 814ms/step - loss: 0.3919
Epoch 100/100
1000/1000 [==============================] - 815s 815ms/step - loss: 0.3937
Early stop count 1/5

进程已结束,退出代码0
